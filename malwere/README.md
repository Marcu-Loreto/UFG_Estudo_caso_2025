# Um Estudo de Caso

## Malware e Seguran√ßa Digital: An√°lise Comparativa com o Dataset TUNADROMD

**Fonte:** [UCI Machine Learning Repository ‚Äì TUNADROMD Dataset](https://archive.ics.uci.edu/dataset/813/tunadromd)
**Autores:** Abhishek Singh e Pankaj Kumar

---

### üéØ Objetivo do Estudo

Este projeto realiza uma **an√°lise explorat√≥ria e preditiva** do dataset *TUNADROMD*, com foco na detec√ß√£o de malwares por meio de modelos de Machine Learning. A abordagem inclui:

* Tratamento e balanceamento da base de dados.
* Treinamento e compara√ß√£o de **tr√™s modelos principais**.
* Aplica√ß√£o de **PCA (Principal Component Analysis)** para redu√ß√£o de dimensionalidade e avalia√ß√£o do *trade-off* entre desempenho e custo computacional.

---

### üß© Etapas do Estudo

#### 1. Importa√ß√£o e Prepara√ß√£o do Ambiente

Foram importadas bibliotecas de an√°lise de dados (*pandas, numpy*), machine learning (*scikit-learn*), estat√≠stica (*scipy*) e visualiza√ß√£o (*matplotlib, seaborn, plotly*).
Essas bibliotecas permitiram estruturar o fluxo de an√°lise e facilitar a compara√ß√£o gr√°fica entre os resultados dos modelos.

#### 2. Leitura e An√°lise Inicial do Dataset

O dataset **TUNADROMD.csv** foi carregado e inspecionado para entender:

* Quantidade de registros e atributos (`tabela.shape`).
* Distribui√ß√£o das classes (coluna `Label`).
* Exist√™ncia de dados ausentes (`dropna()` foi aplicado para limpeza inicial).

Foi identificado **desbalanceamento de classes**, o que motivou o uso de t√©cnicas de **oversampling** para obter uma propor√ß√£o pr√≥xima de **50/50** entre amostras benignas e maliciosas.

#### 3. Balanceamento da Base

A base foi equilibrada com replica√ß√£o controlada da classe minorit√°ria (`sample(replace=True)`), resultando em uma distribui√ß√£o balanceada:

```python
classe_0_oversampled = classe_0.sample(len(classe_1), replace=True, random_state=42)
tabela_balanceada = pd.concat([classe_1, classe_0_oversampled])
```

Isso garantiu uma amostra robusta para o treino, reduzindo o risco de *vi√©s de predi√ß√£o*.

#### 4. Divis√£o de Dados

A base balanceada foi dividida em **80% treino** e **20% teste**:

```python
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
```

#### 5. Treinamento dos Modelos

Tr√™s modelos supervisionados foram treinados e comparados:

| Modelo                  | Tipo                | Finalidade                                      |
| :---------------------- | :------------------ | :---------------------------------------------- |
| **Regress√£o Log√≠stica** | Linear              | Modelo base e interpret√°vel                     |
| **Random Forest**       | Ensemble            | Modelo robusto com m√∫ltiplas √°rvores            |
| **Gradient Boosting**   | Ensemble sequencial | Modelo otimizado para minimizar erros residuais |

Cada modelo foi avaliado com base em **Acur√°cia, Precis√£o, Recall, F1-Score, MSE e AUC-ROC**.

#### 6. Resultados Sem PCA

Os tr√™s modelos apresentaram alta performance, sendo o **Random Forest** o mais consistente nas m√©tricas principais.

**Compara√ß√£o geral (sem PCA):**

| Modelo              | Accuracy | Precision | Recall | F1-Score |   MSE  |
| :------------------ | :------: | :-------: | :----: | :------: | :----: |
| Regress√£o Log√≠stica |  0.9843  |   0.9944  | 0.9861 |  0.9902  | 0.0157 |
| Random Forest       |  0.9944  |   0.9958  | 0.9972 |  0.9965  | 0.0056 |
| Gradient Boosting   |  0.9866  |   0.9876  | 0.9958 |  0.9917  | 0.0134 |

O **Random Forest** apresentou o menor erro quadr√°tico m√©dio e maior *recall*, tornando-se o modelo mais promissor para o cen√°rio original.

---

### üîç Aplica√ß√£o de PCA e An√°lise de Trade-offs

Ap√≥s a defini√ß√£o do melhor modelo, aplicou-se o **PCA (Principal Component Analysis)** sobre o dataset balanceado, mantendo **95% da vari√¢ncia explicada**. O n√∫mero de componentes foi reduzido de forma significativa, diminuindo o custo computacional.

**Resultados da Regress√£o Log√≠stica com PCA:**

| M√©trica  |  Valor |
| :------- | :----: |
| Acur√°cia | 0.9520 |
| Precis√£o | 0.9483 |
| Recall   | 0.9586 |
| F1-Score | 0.9534 |
| MSE      | 0.0480 |
| AUC-ROC  | 0.9712 |

**Redu√ß√£o dimensional:**

* Atributos originais: 242
* Atributos ap√≥s PCA: 58
* **Redu√ß√£o de ~76%**, mantendo 95% da vari√¢ncia dos dados.

**Conclus√£o da Etapa PCA:**
O PCA reduziu drasticamente o custo computacional e manteve boa performance ‚Äî um excelente *trade-off* entre efici√™ncia e precis√£o.

---

### üìà Visualiza√ß√µes e An√°lises Complementares

Foram gerados gr√°ficos interativos com **Plotly** para:

* Matrizes de confus√£o (valores absolutos e normalizados) dos quatro cen√°rios principais:
  *Regress√£o Log√≠stica, Random Forest, Gradient Boosting e Regress√£o Log√≠stica + PCA.*
* Compara√ß√£o de m√©tricas entre todos os modelos (gr√°fico de barras agrupadas).

Essas visualiza√ß√µes destacaram que o **Random Forest** continua com melhor desempenho geral, enquanto o uso de **PCA** proporcionou um modelo mais leve e r√°pido para execu√ß√µes cont√≠nuas.

---

### ‚úÖ Conclus√µes Gerais

1. O tratamento e balanceamento da base eliminaram vi√©s de classifica√ß√£o.
2. O **Random Forest** se destacou como melhor modelo em precis√£o e estabilidade.
3. A aplica√ß√£o de **PCA** mostrou ser eficaz para reduzir dimensionalidade com baixo impacto na performance.
4. O custo computacional foi reduzido em mais de 70%, mantendo **95% da vari√¢ncia** e alta acur√°cia.
5. Este pipeline pode ser replicado para outros datasets de ciberseguran√ßa com ajustes m√≠nimos.

---

üìò **Resumo Final:**
Este estudo evidencia que a combina√ß√£o de **pr√©-processamento de dados**, **avalia√ß√£o de m√∫ltiplos modelos** e **redu√ß√£o de dimensionalidade com PCA** √© uma estrat√©gia eficiente para aplica√ß√µes reais de detec√ß√£o de malware ‚Äî unindo **precis√£o preditiva** e **otimiza√ß√£o de recursos computacionais**.
